// Shared microphone functionality for all game pages
// This module provides M-key push-to-talk functionality

console.log('Loading shared microphone module...');

// Check if Electron IPC is available
let OPENAI_API_KEY = null;

// Initialize API key from main process
(async () => {
  try {
    if (typeof window.electron !== 'undefined' && window.electron.ipcRenderer) {
      OPENAI_API_KEY = await window.electron.ipcRenderer.invoke('get-openai-key');
      console.log('API key loaded for microphone module:', OPENAI_API_KEY ? 'YES' : 'NO');
    } else {
      console.error('Electron IPC not available in microphone module');
    }
  } catch (err) {
    console.error('Failed to load API key in microphone module:', err);
  }
})();

// Microphone variables
let isRecording = false;
let mediaRecorder = null;
let audioChunks = [];
let stream = null;

// Add minimum recording time to prevent very short recordings
const MIN_RECORDING_TIME = 1000; // 1 second minimum
let recordingStartTime = 0;

// Create status elements if they don't exist
function ensureStatusElements() {
  if (!document.getElementById('speechStatus')) {
    const statusDiv = document.createElement('div');
    statusDiv.id = 'speechStatus';
    statusDiv.style.cssText = 'color: red; margin-bottom: 8px; font-weight: bold; padding: 10px; background: #fff3cd; border: 1px solid #ffeaa7; border-radius: 8px;';
    statusDiv.textContent = 'ğŸ™ï¸ M í‚¤ë¥¼ ëˆ„ë¥´ê³  ìˆëŠ” ë™ì•ˆ ë§í•˜ì„¸ìš”';
    
    // Find a good place to insert - after title or at top of container
    const container = document.querySelector('.container') || 
                     document.querySelector('.twentyq-container') ||
                     document.querySelector('body > div') ||
                     document.body;
    
    // Try to insert after any title/heading elements
    const title = container.querySelector('h1, h2, .title, .twentyq-title');
    if (title) {
      title.parentNode.insertBefore(statusDiv, title.nextSibling);
    } else {
      container.insertBefore(statusDiv, container.firstChild);
    }
  }
  
  if (!document.getElementById('inputText')) {
    const inputDiv = document.createElement('div');
    inputDiv.innerHTML = '<strong>ì…ë ¥ í…ìŠ¤íŠ¸:</strong> <span id="inputText" style="color: #1976d2;"></span>';
    inputDiv.style.cssText = 'margin: 10px 0; padding: 8px; background: #e3f2fd; border-radius: 4px;';
    
    const speechStatus = document.getElementById('speechStatus');
    speechStatus.parentNode.insertBefore(inputDiv, speechStatus.nextSibling);
  }
  
  if (!document.getElementById('aiResponse')) {
    const responseDiv = document.createElement('div');
    responseDiv.innerHTML = '<strong>AI ì‘ë‹µ:</strong> <span id="aiResponse" style="color: #388e3c;"></span>';
    responseDiv.style.cssText = 'margin: 10px 0; padding: 8px; background: #e8f5e8; border-radius: 4px;';
    
    const inputDiv = document.querySelector('#inputText').parentNode;
    inputDiv.parentNode.insertBefore(responseDiv, inputDiv.nextSibling);
  }
}

// M key push-to-talk functionality
document.addEventListener('keydown', async (event) => {
  console.log('Shared-mic: Key pressed:', event.code, 'isRecording:', isRecording);
  
  // Update visual indicator
  const speechStatus = document.getElementById('speechStatus');
  if (speechStatus && event.code === 'KeyM') {
    speechStatus.textContent = 'ğŸ™ï¸ ë…¹ìŒ ì¤‘... (Mí‚¤ë¥¼ ë†“ìœ¼ë©´ ì¸ì‹ ì‹œì‘)';
    speechStatus.style.color = '#1976d2';
  }
  
  // Only trigger on M key and if not already recording
  if (event.code === 'KeyM' && !isRecording) {
    console.log('Shared-mic: Starting recording...');
    event.preventDefault();
    recordingStartTime = Date.now(); // Track recording start time
    await startRecording();
  }
});

document.addEventListener('keyup', async (event) => {
  console.log('Shared-mic: Key released:', event.code, 'isRecording:', isRecording);
  
  // Update visual indicator
  const speechStatus = document.getElementById('speechStatus');
  if (speechStatus && event.code === 'KeyM') {
    speechStatus.textContent = 'ğŸ™ï¸ M í‚¤ë¥¼ ëˆ„ë¥´ê³  ìˆëŠ” ë™ì•ˆ ë§í•˜ì„¸ìš”';
    speechStatus.style.color = '#d32f2f';
  }
  
  // Only trigger on M key release and if currently recording
  if (event.code === 'KeyM' && isRecording) {
    console.log('Shared-mic: Stopping recording...');
    event.preventDefault();
    
    const recordingDuration = Date.now() - recordingStartTime;
    if (recordingDuration < MIN_RECORDING_TIME) {
      console.warn('Shared-mic: Recording too short, extending...');
      // Don't stop immediately, let it record for minimum time
      setTimeout(async () => {
        if (isRecording) {
          await stopRecording();
        }
      }, MIN_RECORDING_TIME - recordingDuration);
    } else {
      await stopRecording();
    }
  }
});

async function startRecording() {
  try {
    console.log('Shared-mic: startRecording called');
    ensureStatusElements();
    
    // Test microphone access with enhanced settings for better quality
    let testStream;
    try {
      testStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,
          sampleRate: 16000, // Lower sample rate for better Whisper compatibility
          sampleSize: 16,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      console.log('Shared-mic: Microphone test successful');
    } catch (testError) {
      console.error('Shared-mic: Microphone test failed:', testError);
      const speechStatusElement = document.getElementById('speechStatus');
      isRecording = false;
      
      if (speechStatusElement) {
        if (testError.name === 'NotAllowedError') {
          speechStatusElement.innerHTML = `
            âŒ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.<br>
            <strong>í•´ê²° ë°©ë²•:</strong><br>
            1. ë¸Œë¼ìš°ì €ì—ì„œ ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©<br>
            2. Windows: ì„¤ì • > ê°œì¸ì •ë³´ > ë§ˆì´í¬ì—ì„œ ì•± í—ˆìš©
          `;
        } else if (testError.name === 'NotFoundError') {
          speechStatusElement.textContent = 'âŒ ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
        } else {
          speechStatusElement.textContent = 'âŒ ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜: ' + testError.message;
        }
      }
      return;
    }
    
    isRecording = true;
    audioChunks = [];
    
    const speechStatusElement = document.getElementById('speechStatus');
    if (speechStatusElement) {
      speechStatusElement.textContent = 'ğŸ™ï¸ ë…¹ìŒ ì¤‘... (Mí‚¤ë¥¼ ë†“ìœ¼ë©´ ì¸ì‹ ì‹œì‘)';
      speechStatusElement.style.color = '#1976d2';
    }
    
    stream = testStream;
    
    // Try different audio formats for better compatibility
    let mimeType = 'audio/webm';
    if (!MediaRecorder.isTypeSupported('audio/webm')) {
      if (MediaRecorder.isTypeSupported('audio/mp4')) {
        mimeType = 'audio/mp4';
      } else if (MediaRecorder.isTypeSupported('audio/wav')) {
        mimeType = 'audio/wav';
      }
    }
    
    console.log('Shared-mic: Using audio format:', mimeType);
    
    mediaRecorder = new MediaRecorder(stream, {
      mimeType: mimeType,
      audioBitsPerSecond: 128000 // Higher bit rate for better quality
    });
    
    mediaRecorder.ondataavailable = (event) => {
      console.log('Shared-mic: Audio data available, size:', event.data.size);
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };
    
    mediaRecorder.onstop = async () => {
      console.log('Shared-mic: MediaRecorder stopped');
      if (audioChunks.length > 0) {
        await processAudio();
      }
      
      // Clean up stream
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
      }
    };
    
    mediaRecorder.start();
    console.log('Shared-mic: Recording started');
    
  } catch (error) {
    console.error('Shared-mic: Error starting recording:', error);
    isRecording = false;
    const speechStatusElement = document.getElementById('speechStatus');
    if (speechStatusElement) {
      speechStatusElement.textContent = 'âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: ' + error.message;
    }
  }
}

async function stopRecording() {
  if (!mediaRecorder || !isRecording) {
    console.log('Shared-mic: Not recording, nothing to stop');
    return;
  }
  
  console.log('Shared-mic: Stopping recording...');
  isRecording = false;
  
  const speechStatusElement = document.getElementById('speechStatus');
  if (speechStatusElement) {
    speechStatusElement.textContent = 'â³ ìŒì„± ì¸ì‹ ì¤‘...';
    speechStatusElement.style.color = '#ff9800';
  }
  
  mediaRecorder.stop();
}

async function processAudio() {
  try {
    console.log('Shared-mic: Processing audio...');
    
    if (audioChunks.length === 0) {
      console.error('Shared-mic: No audio data to process');
      return;
    }
    
    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
    console.log('Shared-mic: Audio blob created, size:', audioBlob.size);
    
    if (audioBlob.size < 1000) {
      console.warn('Shared-mic: Audio blob too small, likely no speech');
      const speechStatusElement = document.getElementById('speechStatus');
      if (speechStatusElement) {
        speechStatusElement.textContent = 'âš ï¸ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë” í¬ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”.';
      }
      return;
    }
    
    // Convert to array buffer for Electron IPC
    const arrayBuffer = await audioBlob.arrayBuffer();
    const audioBuffer = new Uint8Array(arrayBuffer);
    
    console.log('Shared-mic: Sending audio to Electron for recognition...');
    
    // Use Electron IPC if available, otherwise fall back to fetch
    let result;
    if (typeof window.electron !== 'undefined' && window.electron.ipcRenderer) {
      try {
        const text = await window.electron.ipcRenderer.invoke('recognize-audio', audioBuffer);
        result = { text: text };
      } catch (ipcError) {
        console.error('Shared-mic: IPC recognition failed:', ipcError);
        throw ipcError;
      }
    } else {
      // Fallback: try HTTP request to Flask server (if it has speech endpoint)
      console.warn('Shared-mic: Electron IPC not available, trying HTTP fallback...');
      const base64Audio = await blobToBase64(audioBlob);
      
      const response = await fetch('http://localhost:5001/speech-to-text', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          audio: base64Audio,
          format: 'webm'
        })
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      result = await response.json();
    }
    
    console.log('Shared-mic: Speech recognition result:', result);
    
    if (result.text) {
      const inputTextSpan = document.getElementById('inputText');
      if (inputTextSpan) {
        inputTextSpan.textContent = result.text;
      }
      
      // Get AI response
      await getAIResponse(result.text);
    } else {
      const speechStatusElement = document.getElementById('speechStatus');
      if (speechStatusElement) {
        speechStatusElement.textContent = 'âš ï¸ ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
      }
    }
    
  } catch (error) {
    console.error('Shared-mic: Error processing audio:', error);
    const speechStatusElement = document.getElementById('speechStatus');
    if (speechStatusElement) {
      // Provide more specific error messages
      if (error.message.includes('Audio unclear')) {
        speechStatusElement.textContent = 'âš ï¸ ìŒì„±ì´ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë” í¬ê³  ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”.';
        speechStatusElement.style.color = '#ff9800';
      } else if (error.message.includes('No speech recognized')) {
        speechStatusElement.textContent = 'âš ï¸ ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê°€ê¹Œì´ì—ì„œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
        speechStatusElement.style.color = '#ff9800';
      } else if (error.message.includes('Audio too short')) {
        speechStatusElement.textContent = 'âš ï¸ ë…¹ìŒ ì‹œê°„ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. Mí‚¤ë¥¼ ë” ì˜¤ë˜ ëˆŒëŸ¬ì£¼ì„¸ìš”.';
        speechStatusElement.style.color = '#ff9800';
      } else {
        speechStatusElement.textContent = 'âŒ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: ' + error.message;
        speechStatusElement.style.color = '#d32f2f';
      }
    }
  }
}

function blobToBase64(blob) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const base64 = reader.result.split(',')[1];
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}

async function getAIResponse(userText) {
  try {
    const speechStatusElement = document.getElementById('speechStatus');
    if (speechStatusElement) {
      speechStatusElement.textContent = 'ğŸ¤– AI ì‘ë‹µ ìƒì„± ì¤‘...';
      speechStatusElement.style.color = '#9c27b0';
    }
    
    if (!OPENAI_API_KEY) {
      throw new Error('OpenAI API key not available');
    }
    
    const messages = [
      {
        role: "system", 
        content: "ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë“¤ì„ ìœ„í•œ ì¹œì ˆí•˜ê³  ì¦ê±°ìš´ í•œêµ­ì–´ ê²Œì„ ë¹„ì„œì…ë‹ˆë‹¤. " +
          "ë‹¹ì‹ ì˜ ì£¼ëœ ì—­í• ì€ ì•„ì´ë“¤ì´ 'ëë§ì‡ê¸°', 'ìˆ«ì ì„¸ê¸° (ì˜ˆ: 369 ê²Œì„)', 'ì í”„ ê²Œì„'ê³¼ ê°™ì€ ê²Œì„ì„ í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤. " +
          "ëª¨ë“  ëŒ€í™”ëŠ” í•œêµ­ì–´ë¡œ ì§„í–‰ë©ë‹ˆë‹¤. " +
          "**ë§¤ìš° ì¤‘ìš”** ë‹¹ì‹ ì˜ ì—­í• ì€ ì§ì ‘ ê²Œì„ì„ ê°™ì´ í•´ì£¼ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì•„ì´ë“¤ì´ ê²Œì„ì„ ì‹œì‘í•˜ê³  ê·œì¹™ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤. " +
          "**ë§¤ìš° ì¤‘ìš”** 369ê²Œì„ì²˜ëŸ¼ í”„ë¡¬í”„íŠ¸ì— ë³€í˜•ëœ ê·œì¹™ì´ ìˆëŠ” ê²½ìš°ì—” ì˜¤ë¡œì§€ ì“°ì—¬ìˆëŠ” ê·œì¹™ë§Œ ë”°ë¼ì•¼í•˜ê³ , ì•Œë ¤ì ¸ìˆëŠ” ê²Œì„ì˜ ê·œì¹™ì€ ì „ë¶€ ë¬´ì‹œí•´ì•¼ í•©ë‹ˆë‹¤." +
          "ì‚¬ìš©ìê°€ ê²Œì„ì„ ì‹œì‘í•˜ë ¤ í•  ë•Œ, ë¨¼ì € ê²Œì„ ì„¤ëª…ì´ í•„ìš”í•œì§€ ë¬¼ì–´ë³´ê³ , ì„¤ëª… ìš”ì²­ ì‹œ ê° ê²Œì„ì˜ ê·œì¹™ì„ ê°„ë‹¨í•˜ê³  ì•Œê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. " +
          "**ë§¤ìš° ì¤‘ìš”:** ë‹¹ì‹ ì€ ì§ì ‘ ê²Œì„ì„ í”Œë ˆì´í•˜ê±°ë‚˜ ê²Œì„ì˜ ì§„í–‰ ìƒí™©ì„ ê´€ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ 'ì‹œì‘í•˜ì'ê³  í•  ë•Œ, í•­ìƒ 'ê²Œì„ì€ í™”ë©´ì— ìˆëŠ” ë²„íŠ¼ì„ ëˆŒëŸ¬ì„œ ì§„í–‰í•´ì£¼ì„¸ìš”!'ì™€ ê°™ì´ ë²„íŠ¼ì„ í†µí•´ ì§„í–‰í•˜ë„ë¡ ì•ˆë‚´í•´ì•¼ í•©ë‹ˆë‹¤. " +
          "ë‹¤ë¥¸ ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì—ëŠ” ë‹µë³€í•˜ì§€ ì•Šê³ , í•­ìƒ ê²Œì„ê³¼ ê´€ë ¨ëœ ëŒ€í™”ë¡œ ìœ ë„í•˜ê±°ë‚˜, ê²Œì„ì„ ì‹œì‘í•˜ë„ë¡ ì•ˆë‚´í•´ì£¼ì„¸ìš”. " +
          "ì´ˆë“±í•™ìƒ ëˆˆë†’ì´ì— ë§ì¶° ì¹œê·¼í•˜ê³  ê¸ì •ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”." +
          "ë‹¨, ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹œì‘í•˜ë¼ëŠ” ë§ì€ ì‹œì‘í•˜ìê³  ë§í•˜ì§€ ì•ŠëŠ” ì´ìƒ í•˜ì§€ ë§ˆì„¸ìš”. ì‹œì‘í•˜ìëŠ” ë§ ì—†ì´ ì§„í–‰í•˜ë ¤ëŠ” ê²½ìš°, ì˜¤ì§ ê·œì¹™ ì„¤ëª…ì´ í•„ìš”í•œì§€ ë¬¼ì–´ë³´ê³  í•„ìš”í•œ ê²½ìš° ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”." +
          "**ë§¤ìš° ì¤‘ìš”** ê·¸ë¦¬ê³  369 ê²Œì„ ê·œì¹™ì„ ì„¤ëª…í• ë•Œ, ëª‡ê°€ì§€ ê·œì¹™ì„ ë‹¤ë¥´ê²Œ í•´ì¤˜ì•¼í•´ìš”. ìš°ì„  'ì§'ì´ ì•„ë‹Œ 'ì½”ì•Œë¼'ë¼ê³  ë§ì„ í•´ì•¼í•˜ê³ , 3ì˜ ë°°ìˆ˜ì¼ ë•Œë§Œ 'ì½”ì•Œë¼'ë¼ê³  ë§í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³ , 3ì˜ ë°°ìˆ˜ê°€ ì•„ë‹Œ ìˆ«ìë¥¼ ë§í• ë•ŒëŠ” ê·¸ëƒ¥ ìˆ«ìë§Œ ë§í•´ì¤˜ì•¼ í•´ìš”. " +
          "3ì´ ë“¤ì–´ê°„ ìˆ«ìì¸ë° 3ì˜ ë°°ìˆ˜ê°€ ì•„ë‹Œ ê²½ìš°ì—”, ì½”ì•Œë¼ê°€ ì•„ë‹ˆê³  ìˆ«ìë¥¼ ì™¸ì³ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 13, 29, 43 ë“±ì€ ê·¸ëƒ¥ ìˆ«ìë§Œ ë§í•´ì•¼ í•©ë‹ˆë‹¤. " +
          "ëë§ì‡ê¸° ê²Œì„ì€ í•œêµ­ì–´ ë‹¨ì–´ë¥¼ ì´ì–´ê°€ëŠ” ê²Œì„ì…ë‹ˆë‹¤. " +
          "ê²Œì„ì„ ì‹œì‘í•  ë•Œ, ì²« ë²ˆì§¸ í”Œë ˆì´ì–´ê°€ ë‹¨ì–´ë¥¼ ë§í•˜ë©´ ë‹¤ìŒ í”Œë ˆì´ì–´ëŠ” ê·¸ ë‹¨ì–´ì˜ ë§ˆì§€ë§‰ ê¸€ìë¡œ ì‹œì‘í•˜ëŠ” ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ë§í•´ì•¼ í•©ë‹ˆë‹¤. " +
          "ì˜ˆë¥¼ ë“¤ì–´, ì²« ë²ˆì§¸ í”Œë ˆì´ì–´ê°€ 'ì‚¬ê³¼'ë¼ê³  í•˜ë©´, ë‘ ë²ˆì§¸ í”Œë ˆì´ì–´ëŠ” 'ê³¼ì¼' ê°™ì€ ë‹¨ì–´ë¥¼ ë§í•´ì•¼ í•©ë‹ˆë‹¤. " +
          "ë‹¨, ì´ë¯¸ ì‚¬ìš©ëœ ë‹¨ì–´ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë©°, ë‹¨ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë„ íƒˆë½í•˜ê²Œ ë©ë‹ˆë‹¤. " +
          "ë˜í•œ, ëë§ì‡ê¸° ê·œì¹™ì— ë”°ë¼ ë‘ìŒë²•ì¹™ì„ ì ìš©í•˜ì—¬ ë‹¨ì–´ë¥¼ ì´ì–´ê°€ì•¼ í•©ë‹ˆë‹¤. " +
          "ê²Œì„ì€ ëª¨ë‘ ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë‘ ì› ì „ì²´ê°€ í•¨ê»˜ ì°¸ì—¬í•´ì•¼ í•©ë‹ˆë‹¤. " +
          "ë§Œì•½ ëª¨ë‘ ì›ì´ í•œ ëª…ì´ë¼ë„ ê·œì¹™ì„ ì–´ê¸°ê±°ë‚˜ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ ëª¨ë‘ ì€ íƒˆë½í•˜ê²Œ ë©ë‹ˆë‹¤." +
          "ì í”„ê²Œì„ì´ë¼ëŠ” ê²ƒì€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²Œì„ì´ë©°, ê·œì¹™ì€ ì˜¤ë¡œì§€ ì•„ë˜ ì„¤ëª…ëŒ€ë¡œ ì½ê³  ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. " +
          "ì í”„ê²Œì„ì€ ì»´í“¨í„°ì— ì¨ì ¸ìˆëŠ” ìˆ«ì ë§Œí¼ ì í”„ë¥¼ ì—°ì†ì ìœ¼ë¡œ í•´ì•¼í•˜ëŠ”ë°, ì´ ë•Œ ì í”„ëŠ” 1ë¶€í„° 10ê¹Œì§€ì˜ ìˆ«ì ì¤‘ í•˜ë‚˜ë¥¼ AIê°€ ì„ì˜ë¡œ ì„ íƒí•©ë‹ˆë‹¤. " +
          "ì´ ë•Œ, ì‚¬ìš©ìëŠ” AIê°€ ì„ íƒí•œ ìˆ«ìë§Œí¼ ì í”„ë¥¼ í•´ì•¼í•˜ë©°, ë§Œì•½ ì‚¬ìš©ìê°€ ì í”„ë¥¼ í•˜ì§€ ì•Šê±°ë‚˜, ì‹œê°„ ì•ˆì— ëª»í•˜ê±°ë‚˜, ë§í•œ ìˆ«ìë³´ë‹¤ ë”, ë˜ëŠ” ëœ í•˜ê²Œ ë˜ë©´ ì‹¤íŒ¨í•˜ê²Œ ë©ë‹ˆë‹¤. " +
          "ì í”„ê²Œì„ì€ ëª¨ë‘ ìœ¼ë¡œ í• ë•Œ ê·œì¹™ì´ í•˜ë‚˜ ë” ì¶”ê°€ë˜ëŠ”ë°, ì í”„ë¥¼ í• ë•Œ ë°˜ë“œì‹œ íŒ€ì› ì „ì²´ê°€ ê°™ì´ ì í”„ë¥¼ í•´ì•¼í•©ë‹ˆë‹¤. " +
          "ëª¨ë‘ ìœ¼ë¡œ ì í”„í• ë•Œ ì‹œê°„ì•ˆì— ì í”„í•˜ê³  ëª¨ë“  ë‹¤ë¥¸ ê·œì¹™ì„ ì¤€ìˆ˜í•´ë„ ë‹¤ê°™ì´ ì í”„ë¥¼ í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ê·¸ íŒ€ì€ ì‹¤íŒ¨í•˜ê²Œ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤." +
          "**ë§¤ìš° ì¤‘ìš”:** ë‹¹ì‹ ì´ ëŒ€í™”í•˜ëŠ” ì£¼ìš” ì—°ë ¹ì¸µì€ ì´ˆë“±í•™ìƒë“¤ì´ê¸° ë•Œë¬¸ì— ëŒ€í™” ë°©ì‹ì€ í•­ìƒ ì¹œê·¼í•˜ê³  ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ì„œ ëª¨ë“  ëŒ€í™”ëŠ” ë°˜ë§ë¡œ ì§„í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
      },
      {
        role: "user",
        content: userText
      }
    ];
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: messages,
        max_tokens: 200,
        temperature: 0.7
      })
    });
    
    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }
    
    const data = await response.json();
    const aiResponse = data.choices[0].message.content;
    
    const aiResponseSpan = document.getElementById('aiResponse');
    if (aiResponseSpan) {
      aiResponseSpan.textContent = aiResponse;
    }
    
    // Speak the response
    speakText(aiResponse);
    
    if (speechStatusElement) {
      speechStatusElement.textContent = 'âœ… ì™„ë£Œ! M í‚¤ë¥¼ ëˆ„ë¥´ê³  ìˆëŠ” ë™ì•ˆ ë§í•˜ì„¸ìš”';
      speechStatusElement.style.color = '#4caf50';
    }
    
  } catch (error) {
    console.error('Shared-mic: Error getting AI response:', error);
    const speechStatusElement = document.getElementById('speechStatus');
    if (speechStatusElement) {
      speechStatusElement.textContent = 'âŒ AI ì‘ë‹µ ì˜¤ë¥˜: ' + error.message;
    }
  }
}

function speakText(text) {
  if ('speechSynthesis' in window) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = 0.9;
    utterance.pitch = 1.0;
    
    // Try to use Korean voice if available
    const voices = speechSynthesis.getVoices();
    const koreanVoice = voices.find(voice => voice.lang === 'ko-KR');
    if (koreanVoice) {
      utterance.voice = koreanVoice;
    }
    
    speechSynthesis.speak(utterance);
  }
}

// Initialize status elements when the page loads
document.addEventListener('DOMContentLoaded', () => {
  ensureStatusElements();
  console.log('Shared microphone module initialized');
});

// Also try to initialize immediately in case DOMContentLoaded already fired
if (document.readyState === 'loading') {
  // Still loading, wait for DOMContentLoaded
} else {
  // Already loaded
  ensureStatusElements();
  console.log('Shared microphone module initialized (immediate)');
}
