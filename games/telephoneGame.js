// telephoneGame.js - Telephone Game with OpenAI API for answer checking
let OPENAI_API_KEY = null;

// Initialize API key from main process
(async () => {
  try {
    if (typeof window.electron !== 'undefined' && window.electron.ipcRenderer) {
      OPENAI_API_KEY = await window.electron.ipcRenderer.invoke('get-openai-key');
      console.log('API key loaded:', OPENAI_API_KEY ? 'YES' : 'NO');
    } else {
      console.error('Electron IPC not available - running in browser?');
    }
  } catch (err) {
    console.error('Failed to load API key:', err);
  }
})();
// Example action prompts in Korean (ë°˜ë§)
const prompts = [
  "ì•‰ì•„", "ì¼ì–´ë‚˜", "ì í”„í•´", "ë°•ìˆ˜ì³", "ì† í”ë“¤ì–´", "ëŒì•„", "ë°œë ë§Œì ¸", "ì† ë“¤ì–´", "ë„ë•ì—¬", "ê³ ê°œ ì €ì–´", "ë‹¬ë ¤", "ê±¸ì–´", "í•œ ë°œë¡œ ë›°ì–´", "ì›ƒì–´", "í•˜í’ˆí•´", "ëˆˆ ê¹œë¹¡ì—¬", "ê¸°ì§€ê°œ ì¼œ", "ê°€ë¦¬ì¼œ", "ê¸°ì¹¨í•´", "ì›ƒì–´ë´"
];

const messages = [
  {
    role: "system",
    content: "ë„ˆëŠ” ì–´ë¦°ì´ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì œì‹œì–´ ê²Œì„ì˜ ì±„ì  ë„ìš°ë¯¸ì•¼. ì‚¬ìš©ìê°€ ë‹¨ì–´ ë‘ê°œë¥¼ ì œì‹œí• ê±°ì•¼. ì²« ë‹¨ì–´ëŠ” ì›ë˜ ì œì‹œì–´. ì•„ì´ê°€ ì“´ ë‹µì´ ë‘ë²ˆì§¸ ë‹¨ì–´ì•¼. ì•„ì´ì˜ ë‹µì´ ì›ë˜ ì œì‹œì–´ì™€ ì˜ë¯¸ê°€ ë¹„ìŠ·í•˜ê±°ë‚˜, ë™ì‚¬/ëª…ì‚¬ ë³€í˜•(ì˜ˆ: 'ë°•ìˆ˜ì³'ì™€ 'ë°•ìˆ˜', 'ì¼ì–´ë‚˜'ì™€ 'ì¼ì–´ë‚¨', 'ì›ƒì–´'ì™€ 'ì›ƒìŒ')ì²˜ëŸ¼ í˜•íƒœê°€ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ 'ì •ë‹µì´ì•¼!', ì•„ë‹ˆë©´ 'í‹€ë ¸ì–´!'ë§Œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´. ë„ì–´ì“°ê¸°, ì¡°ì‚¬, ì–´ë¯¸, ë§ì¶¤ë²•ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ì •ë‹µìœ¼ë¡œ ì¸ì •í•´."
  }
];

const oppositeMessages = [
  {
    role: "system", 
    content: "ë„ˆëŠ” ì–´ë¦°ì´ ì´ˆë“±í•™ìƒì„ ìœ„í•œ 'ë°˜ëŒ€ë§ ê²Œì„'ì˜ ì±„ì  ë„ìš°ë¯¸ì•¼. ì‚¬ìš©ìê°€ ë‹¨ì–´ ë‘ê°œë¥¼ ì œì‹œí• ê±°ì•¼. ì²« ë‹¨ì–´ëŠ” ì›ë˜ ì œì‹œì–´. ì•„ì´ê°€ ì“´ ë‹µì´ ë‘ë²ˆì§¸ ë‹¨ì–´ì•¼. ì•„ì´ì˜ ë‹µì´ ì›ë˜ ì œì‹œì–´ì˜ ë°˜ëŒ€ ì˜ë¯¸ì´ê±°ë‚˜ ë°˜ëŒ€ í–‰ë™ì´ë©´ 'ì •ë‹µì´ì•¼!', ì•„ë‹ˆë©´ 'í‹€ë ¸ì–´!'ë§Œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´. ì˜ˆì‹œ: 'ì•‰ì•„'ì˜ ë°˜ëŒ€ëŠ” 'ì¼ì–´ë‚˜/ì„œ/ì¼ì–´ì„œê¸°/ì¼ì–´ì„œë‹¤/ìë¦¬ì—ì„œ ì¼ì–´ë‚˜', 'ì›ƒì–´'ì˜ ë°˜ëŒ€ëŠ” 'ìš¸ì–´/ìš¸ê¸°/ìš´ë‹¤', 'ë“¤ì–´'ì˜ ë°˜ëŒ€ëŠ” 'ë‚˜ê°€/ë°–ìœ¼ë¡œ/ë‚˜ê°€ê¸°', 'ìœ„ë¡œ'ì˜ ë°˜ëŒ€ëŠ” 'ì•„ë˜ë¡œ/ë°‘ìœ¼ë¡œ' ë“±. ë„ì–´ì“°ê¸°, ì¡°ì‚¬, ì–´ë¯¸, ë§ì¶¤ë²•ì´ ë‹¬ë¼ë„ ë°˜ëŒ€ ì˜ë¯¸ê°€ ë§ìœ¼ë©´ ì •ë‹µìœ¼ë¡œ ì¸ì •í•´. ë˜í•œ ë™ì‚¬/ëª…ì‚¬ ë³€í˜•(ì˜ˆ: 'ì¼ì–´ë‚˜'ì™€ 'ì¼ì–´ë‚¨', 'ì¼ì–´ì„œê¸°', 'ì¼ì–´ì„œë‹¤')ì²˜ëŸ¼ í˜•íƒœê°€ ë‹¬ë¼ë„ ë°˜ëŒ€ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ì •ë‹µìœ¼ë¡œ ì¸ì •í•´."
  }
];

let currentPrompt = "";

function isOppositeMode() {
  return document.getElementById('oppositeMode').checked;
}

function pickPrompt() {
  currentPrompt = prompts[Math.floor(Math.random() * prompts.length)];
}

function showPrompt() {
  const promptDisplay = document.getElementById('promptDisplay');
  if (isOppositeMode()) {
    promptDisplay.textContent = currentPrompt + "ì˜ ë°˜ëŒ€";
    promptDisplay.style.color = '#d32f2f'; // Red color for opposite mode
  } else {
    promptDisplay.textContent = currentPrompt;
    promptDisplay.style.color = '#1976d2'; // Original blue color
  }
  promptDisplay.style.display = 'block';
  setTimeout(() => {
    promptDisplay.style.display = 'none';
    document.getElementById('showPromptBtn').style.display = 'none';
    document.getElementById('userAnswer')?.disabled && (document.getElementById('userAnswer').disabled = false);
    document.querySelector('#answerForm button')?.disabled && (document.querySelector('#answerForm button').disabled = false);
    document.getElementById('userAnswer')?.focus();
  }, 5000);
}

window.onload = function() {
  pickPrompt();
  document.getElementById('showPromptBtn').onclick = showPrompt;

  // Add event listener for opposite mode toggle
  document.getElementById('oppositeMode').onchange = function() {
    // Reset the game when mode changes
    pickPrompt();
    document.getElementById('promptDisplay').style.display = 'none';
    document.getElementById('showPromptBtn').style.display = 'inline-block';
    document.getElementById('voiceInputDisplay').textContent = '';
    document.getElementById('resultDisplay').textContent = '';
  };

  // OpenAI Whisper Speech Recognition Setup with M Key Push-to-Talk
  let isRecording = false;
  let mediaRecorder;
  let audioChunks = [];

  function setupSpeechRecognition() {
    // Show speech instructions
    const instructionsDiv = document.createElement('div');
    instructionsDiv.innerHTML = `
      <div style="background: #e3f2fd; padding: 12px; border-radius: 8px; margin: 15px 0; font-size: 0.95em; color: #1976d2;">
        <strong>ìŒì„± ì…ë ¥:</strong> M í‚¤ë¥¼ ëˆ„ë¥´ê³  ìˆëŠ” ë™ì•ˆ ë§í•˜ì„¸ìš”. í‚¤ë¥¼ ë–¼ë©´ ìŒì„±ì´ ì¸ì‹ë©ë‹ˆë‹¤.
      </div>
    `;
    const container = document.querySelector('.twentyq-container, .game-container');
    if (container) {
      container.insertBefore(instructionsDiv, container.children[1]);
    }

    // M key push-to-talk functionality
    document.addEventListener('keydown', function(event) {
      if (event.key === 'm' || event.key === 'M') {
        if (!isRecording && currentPrompt) {
          startRecording();
        }
      }
    });

    document.addEventListener('keyup', function(event) {
      if (event.key === 'm' || event.key === 'M') {
        if (isRecording) {
          stopRecording();
        }
      }
    });
  }

  async function startRecording() {
    if (isRecording || !currentPrompt) return;
    
    try {
      isRecording = true;
      audioChunks = [];
      
      const voiceInputDisplay = document.getElementById('voiceInputDisplay');
      
      voiceInputDisplay.textContent = 'ğŸ¤ Recording... (Release M key to stop)';
      
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      
      mediaRecorder.ondataavailable = function(event) {
        audioChunks.push(event.data);
      };
      
      mediaRecorder.onstop = async function() {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        await processAudio(audioBlob);
        
        // Stop all tracks
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorder.start();
      
    } catch (err) {
      console.error('Error starting recording:', err);
      isRecording = false;
      const voiceInputDisplay = document.getElementById('voiceInputDisplay');
      voiceInputDisplay.textContent = 'Error: Could not access microphone';
    }
  }

  function stopRecording() {
    if (!isRecording || !mediaRecorder) return;
    
    isRecording = false;
    mediaRecorder.stop();
    document.getElementById('voiceInputDisplay').textContent = 'ğŸ”„ Processing speech...';
  }

  async function processAudio(audioBlob) {
    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const buffer = window.electron.bufferFrom(arrayBuffer);
      
      const transcript = await window.electron.ipcRenderer.invoke('recognize-audio', buffer);
      
      const voiceInputDisplay = document.getElementById('voiceInputDisplay');
      
      if (transcript && transcript.trim()) {
        voiceInputDisplay.textContent = 'ì…ë ¥: ' + transcript.trim();
        
        // Auto-grade the answer
        await gradeAnswer(transcript.trim());
      } else {
        voiceInputDisplay.textContent = 'âŒ No speech detected';
      }
    } catch (err) {
      console.error('Speech recognition error:', err);
      const voiceInputDisplay = document.getElementById('voiceInputDisplay');
      voiceInputDisplay.textContent = 'âŒ Speech recognition failed';
    }
  }

  async function gradeAnswer(transcript) {
    if (!OPENAI_API_KEY) {
      document.getElementById('resultDisplay').textContent = 'API í‚¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
      return;
    }
    
    document.getElementById('resultDisplay').textContent = 'ì±„ì  ì¤‘...';
    
    // Choose the appropriate message system based on mode
    const currentMessages = isOppositeMode() ? [...oppositeMessages] : [...messages];
    
    if (isOppositeMode()) {
      currentMessages.push({
        role: 'user', 
        content: 'ì›ë˜ ì œì‹œì–´ëŠ”: ' + currentPrompt + '. ì•„ì´ê°€ ì“´ ë°˜ëŒ€ë§ ë‹µì€: ' + transcript
      });
    } else {
      currentMessages.push({
        role: 'user',
        content: 'ì›ë˜ ì œì‹œì–´ëŠ”: ' + currentPrompt + '. ì•„ì´ê°€ ì“´ ë‹µì€ ' + transcript
      });
    }
    
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
            "Authorization": `Bearer ${OPENAI_API_KEY}`,
            "Content-Type": "application/json"
        },
        body: JSON.stringify({
            model: "gpt-3.5-turbo",
            messages: currentMessages
        })
    });
    const data = await response.json();
    let reply = data.choices[0].message.content.trim();
    document.getElementById('resultDisplay').textContent = reply;
  }

  // Setup speech recognition
  setupSpeechRecognition();
};
